{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Chat with your PDF files using LlamaIndex, Astra DB (Apache Cassandra), and Gradient's open-source models, including LLama2 and Streamlit, all designed for seamless interaction with PDF files.\n",
        "\n",
        "[**Link to my YouTube Channel**](https://www.youtube.com/BhaveshBhatt8791?sub_confirmation=1)\n",
        "\n",
        "Click on the link below to open a Colab version of the notebook. You will be able to create your own version."
      ],
      "metadata": {
        "id": "sbzI6KKiDv78"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhattbhavesh91//pdf-q-a-llamaindex-llama2/blob/main/pdf-q-a-notebook.ipynb\" target=\"_blank\"><img height=\"40\" alt=\"Run your own notebook in Colab\" src = \"https://colab.research.google.com/assets/colab-badge.svg\"></a>"
      ],
      "metadata": {
        "id": "iW1MO9bXD964"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation"
      ],
      "metadata": {
        "id": "XaiKzsSw4FBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "loader = PyPDFLoader(\"the-great-gatsby.pdf\")\n",
        "pages = loader.load_and_split()\n"
      ],
      "metadata": {
        "id": "OL-2E2-xEMoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=500)\n",
        "texts = text_splitter.split_documents(pages)\n",
        "print(len(texts))\n",
        "# for i, doc in enumerate(texts[190:193]):\n",
        "#     print(f\"--- Chunk {i+1} ---\")\n",
        "#     print(doc.page_content[:999])  # print first 500 characters of each\n",
        "#     print()\n"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKWYgjDfRIqA",
        "outputId": "5bb81ac6-d469-4cb3-a3b0-dead876282c9"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "193\n",
            "Download free eBooks of classic literature, books and \n",
            "novels at Planet eBook. Subscribe to our free eBooks blog \n",
            "and email newsletter.\n",
            "The Great Gatsby\n",
            "By F. Scott Fitzgerald\n",
            "\u00181Free eBooks at Planet eBook.com\n",
            "somewhere last night. Iâ€™ve been drunk for about a week now, \n",
            "and I thought it might sober me up to sit in a library.â€™\n",
            "â€˜Has it?â€™\n",
            "â€˜A little bit, I think. I canâ€™t tell yet. Iâ€™ve only been here an \n",
            "hour. Did I tell you about the books? Theyâ€™re real. Theyâ€™reâ€”\n",
            "â€”â€˜\n",
            "â€˜You told us.â€™\n",
            "We shook hands with him gravely and went back out -\n",
            "doors.\n",
            "There was dancing now on the canvas in the garden, \n",
            "old men pushing young girls backward in eternal grace -\n",
            "less circles, superior cou\n",
            "1\u0018\u0018Free eBooks at Planet eBook.com\n",
            "this continent, compelled into an aesthetic contemplation \n",
            "he neither understood nor desired, face to face for the last \n",
            "time in history with something commensurate to his capac-\n",
            "ity for wonder.\n",
            "And as I sat there brooding on the old, unknown world, \n",
            "I thought of Gatsbyâ€™s wonder when he first picked out the \n",
            "green light at the end of Daisyâ€™s dock. He had come a long \n",
            "way to this blue lawn and his dream must have seemed so \n",
            "close that he could hardly fail to gra\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "    model_kwargs={\"device\": \"cpu\"}\n",
        ")\n",
        "\n",
        "db = FAISS.from_documents(texts, embeddings)\n",
        "retriever = db.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "docs = retriever.get_relevant_documents(\"What is the plot of The Great Gatsby?\")\n",
        "for i, doc in enumerate(docs):\n",
        "    print(f\"\\n--- Retrieved chunk {i+1} ---\\n{doc.page_content[:400]}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nz4p9BPwENMe",
        "outputId": "b43ba0a9-305e-4452-9530-1b2a1b78b41d"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Retrieved chunk 1 ---\n",
            "The Great Gatsby1\u0018\u0018\n",
            "and get some sleep.â€™\n",
            "He shook his head.\n",
            "â€˜I want to wait here till Daisy goes to bed. Good night, \n",
            "old sport.â€™\n",
            "He put his hands in his coat pockets and turned back \n",
            "eagerly to his scrutiny of the house, as though my presence \n",
            "marred the sacredness of the vigil. So I walked away and left \n",
            "him standing there in the moonlightâ€”watching over noth -\n",
            "ing.\n",
            "\n",
            "--- Retrieved chunk 2 ---\n",
            "The Great Gatsby1\u0018\u0018\n",
            "hand.\n",
            "That force took shape in the middle of spring with the ar-\n",
            "rival of Tom Buchanan. There was a wholesome bulkiness \n",
            "about his person and his position and Daisy was flattered. \n",
            "Doubtless there was a certain struggle and a certain relief. \n",
            "The letter reached Gatsby while he was still at Oxford.\n",
            "It was dawn now on Long Island and we went about open-\n",
            "ing the rest of the window\n",
            "\n",
            "--- Retrieved chunk 3 ---\n",
            "The Great Gatsby\u0018\u0018\n",
            "flounced over to the dog, kissed it with ecstasy and swept \n",
            "into the kitchen, implying that a dozen chefs awaited her \n",
            "orders there.\n",
            "â€˜Iâ€™ve done some nice things out on Long Island,â€™ asserted \n",
            "Mr. McKee.\n",
            "Tom looked at him blankly.\n",
            "â€˜Two of them we have framed downstairs.â€™\n",
            "â€˜Two what?â€™ demanded Tom.\n",
            "â€˜Two studies. One of them I call â€˜Montauk Pointâ€”the \n",
            "Gulls,â€™ and the other I call â€˜M\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-82-affd95b59ab7>:12: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  docs = retriever.get_relevant_documents(\"What is the plot of The Great Gatsby?\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms.base import LLM\n",
        "from typing import Optional, List, Mapping, Any\n",
        "import requests\n",
        "import os\n",
        "\n",
        "# Set your API key first\n",
        "os.environ[\"OPENROUTER_API_KEY\"] = \"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\"\n",
        "\n",
        "class OpenRouterLLM(LLM):\n",
        "    model: str = \"deepseek/deepseek-chat-v3-0324:free\"\n",
        "\n",
        "    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:\n",
        "        headers = {\n",
        "            \"Authorization\": f\"Bearer {os.environ['OPENROUTER_API_KEY']}\",\n",
        "            \"Content-Type\": \"application/json\",\n",
        "        }\n",
        "        body = {\n",
        "            \"model\": self.model,\n",
        "            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
        "        }\n",
        "        response = requests.post(\n",
        "            \"https://openrouter.ai/api/v1/chat/completions\",\n",
        "            headers=headers,\n",
        "            json=body\n",
        "        )\n",
        "        data = response.json()\n",
        "        return data[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "    @property\n",
        "    def _identifying_params(self) -> Mapping[str, Any]:\n",
        "        return {\"model\": self.model}\n",
        "\n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        return \"openrouter\"\n"
      ],
      "metadata": {
        "id": "HvAEmc9OERzv"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import requests\n",
        "# import os\n",
        "\n",
        "# headers = {\n",
        "#     \"Authorization\": f\"Bearer {os.environ['OPENROUTER_API_KEY']}\",\n",
        "# }\n",
        "# response = requests.get(\"https://openrouter.ai/api/v1/models\", headers=headers)\n",
        "\n",
        "# models = response.json().get(\"data\", [])\n",
        "# for model in models:\n",
        "#     print(\"-\", model.get(\"id\"))\n"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydbZuSZcMRtN",
        "outputId": "d9464669-9f71-4079-a7cb-19efdf331c16"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- microsoft/phi-4-reasoning-plus:free\n",
            "- microsoft/phi-4-reasoning-plus\n",
            "- microsoft/phi-4-reasoning:free\n",
            "- qwen/qwen3-0.6b-04-28:free\n",
            "- inception/mercury-coder-small-beta\n",
            "- qwen/qwen3-1.7b:free\n",
            "- qwen/qwen3-4b:free\n",
            "- opengvlab/internvl3-14b:free\n",
            "- opengvlab/internvl3-2b:free\n",
            "- deepseek/deepseek-prover-v2:free\n",
            "- deepseek/deepseek-prover-v2\n",
            "- meta-llama/llama-guard-4-12b\n",
            "- qwen/qwen3-30b-a3b:free\n",
            "- qwen/qwen3-30b-a3b\n",
            "- qwen/qwen3-8b:free\n",
            "- qwen/qwen3-8b\n",
            "- qwen/qwen3-14b:free\n",
            "- qwen/qwen3-14b\n",
            "- qwen/qwen3-32b:free\n",
            "- qwen/qwen3-32b\n",
            "- qwen/qwen3-235b-a22b:free\n",
            "- qwen/qwen3-235b-a22b\n",
            "- tngtech/deepseek-r1t-chimera:free\n",
            "- thudm/glm-z1-rumination-32b\n",
            "- thudm/glm-z1-9b:free\n",
            "- thudm/glm-4-9b:free\n",
            "- microsoft/mai-ds-r1:free\n",
            "- google/gemini-2.5-pro-preview-03-25\n",
            "- thudm/glm-z1-32b:free\n",
            "- thudm/glm-z1-32b\n",
            "- thudm/glm-4-32b:free\n",
            "- thudm/glm-4-32b\n",
            "- google/gemini-2.5-flash-preview\n",
            "- google/gemini-2.5-flash-preview:thinking\n",
            "- openai/o4-mini-high\n",
            "- openai/o3\n",
            "- openai/o4-mini\n",
            "- shisa-ai/shisa-v2-llama3.3-70b:free\n",
            "- qwen/qwen2.5-coder-7b-instruct\n",
            "- openai/gpt-4.1\n",
            "- openai/gpt-4.1-mini\n",
            "- openai/gpt-4.1-nano\n",
            "- eleutherai/llemma_7b\n",
            "- alfredpros/codellama-7b-instruct-solidity\n",
            "- arliai/qwq-32b-arliai-rpr-v1:free\n",
            "- agentica-org/deepcoder-14b-preview:free\n",
            "- moonshotai/kimi-vl-a3b-thinking:free\n",
            "- x-ai/grok-3-mini-beta\n",
            "- x-ai/grok-3-beta\n",
            "- nvidia/llama-3.3-nemotron-super-49b-v1:free\n",
            "- nvidia/llama-3.3-nemotron-super-49b-v1\n",
            "- nvidia/llama-3.1-nemotron-ultra-253b-v1:free\n",
            "- meta-llama/llama-4-maverick:free\n",
            "- meta-llama/llama-4-maverick\n",
            "- meta-llama/llama-4-scout:free\n",
            "- meta-llama/llama-4-scout\n",
            "- all-hands/openhands-lm-32b-v0.1\n",
            "- mistral/ministral-8b\n",
            "- deepseek/deepseek-v3-base:free\n",
            "- scb10x/llama3.1-typhoon2-8b-instruct\n",
            "- scb10x/llama3.1-typhoon2-70b-instruct\n",
            "- allenai/molmo-7b-d:free\n",
            "- bytedance-research/ui-tars-72b:free\n",
            "- qwen/qwen2.5-vl-3b-instruct:free\n",
            "- google/gemini-2.5-pro-exp-03-25\n",
            "- qwen/qwen2.5-vl-32b-instruct:free\n",
            "- qwen/qwen2.5-vl-32b-instruct\n",
            "- deepseek/deepseek-chat-v3-0324:free\n",
            "- deepseek/deepseek-chat-v3-0324\n",
            "- featherless/qwerky-72b:free\n",
            "- openai/o1-pro\n",
            "- mistralai/mistral-small-3.1-24b-instruct:free\n",
            "- mistralai/mistral-small-3.1-24b-instruct\n",
            "- open-r1/olympiccoder-32b:free\n",
            "- google/gemma-3-1b-it:free\n",
            "- google/gemma-3-4b-it:free\n",
            "- google/gemma-3-4b-it\n",
            "- ai21/jamba-1.6-large\n",
            "- ai21/jamba-1.6-mini\n",
            "- google/gemma-3-12b-it:free\n",
            "- google/gemma-3-12b-it\n",
            "- cohere/command-a\n",
            "- openai/gpt-4o-mini-search-preview\n",
            "- openai/gpt-4o-search-preview\n",
            "- rekaai/reka-flash-3:free\n",
            "- google/gemma-3-27b-it:free\n",
            "- google/gemma-3-27b-it\n",
            "- thedrummer/anubis-pro-105b-v1\n",
            "- thedrummer/skyfall-36b-v2\n",
            "- microsoft/phi-4-multimodal-instruct\n",
            "- perplexity/sonar-reasoning-pro\n",
            "- perplexity/sonar-pro\n",
            "- perplexity/sonar-deep-research\n",
            "- deepseek/deepseek-r1-zero:free\n",
            "- qwen/qwq-32b:free\n",
            "- qwen/qwq-32b\n",
            "- moonshotai/moonlight-16b-a3b-instruct:free\n",
            "- nousresearch/deephermes-3-llama-3-8b-preview:free\n",
            "- openai/gpt-4.5-preview\n",
            "- google/gemini-2.0-flash-lite-001\n",
            "- anthropic/claude-3.7-sonnet\n",
            "- anthropic/claude-3.7-sonnet:thinking\n",
            "- anthropic/claude-3.7-sonnet:beta\n",
            "- perplexity/r1-1776\n",
            "- mistralai/mistral-saba\n",
            "- cognitivecomputations/dolphin3.0-r1-mistral-24b:free\n",
            "- cognitivecomputations/dolphin3.0-mistral-24b:free\n",
            "- meta-llama/llama-guard-3-8b\n",
            "- openai/o3-mini-high\n",
            "- deepseek/deepseek-r1-distill-llama-8b\n",
            "- google/gemini-2.0-flash-001\n",
            "- qwen/qwen-vl-plus\n",
            "- aion-labs/aion-1.0\n",
            "- aion-labs/aion-1.0-mini\n",
            "- aion-labs/aion-rp-llama-3.1-8b\n",
            "- qwen/qwen-vl-max\n",
            "- qwen/qwen-turbo\n",
            "- qwen/qwen2.5-vl-72b-instruct:free\n",
            "- qwen/qwen2.5-vl-72b-instruct\n",
            "- qwen/qwen-plus\n",
            "- qwen/qwen-max\n",
            "- openai/o3-mini\n",
            "- deepseek/deepseek-r1-distill-qwen-1.5b\n",
            "- mistralai/mistral-small-24b-instruct-2501:free\n",
            "- mistralai/mistral-small-24b-instruct-2501\n",
            "- deepseek/deepseek-r1-distill-qwen-32b:free\n",
            "- deepseek/deepseek-r1-distill-qwen-32b\n",
            "- deepseek/deepseek-r1-distill-qwen-14b:free\n",
            "- deepseek/deepseek-r1-distill-qwen-14b\n",
            "- perplexity/sonar-reasoning\n",
            "- perplexity/sonar\n",
            "- liquid/lfm-7b\n",
            "- liquid/lfm-3b\n",
            "- deepseek/deepseek-r1-distill-llama-70b:free\n",
            "- deepseek/deepseek-r1-distill-llama-70b\n",
            "- deepseek/deepseek-r1:free\n",
            "- deepseek/deepseek-r1\n",
            "- minimax/minimax-01\n",
            "- mistralai/codestral-2501\n",
            "- microsoft/phi-4\n",
            "- deepseek/deepseek-chat:free\n",
            "- deepseek/deepseek-chat\n",
            "- sao10k/l3.3-euryale-70b\n",
            "- openai/o1\n",
            "- eva-unit-01/eva-llama-3.33-70b\n",
            "- x-ai/grok-2-vision-1212\n",
            "- x-ai/grok-2-1212\n",
            "- cohere/command-r7b-12-2024\n",
            "- google/gemini-2.0-flash-exp:free\n",
            "- meta-llama/llama-3.3-70b-instruct:free\n",
            "- meta-llama/llama-3.3-70b-instruct\n",
            "- amazon/nova-lite-v1\n",
            "- amazon/nova-micro-v1\n",
            "- amazon/nova-pro-v1\n",
            "- qwen/qwq-32b-preview:free\n",
            "- qwen/qwq-32b-preview\n",
            "- google/learnlm-1.5-pro-experimental:free\n",
            "- eva-unit-01/eva-qwen-2.5-72b\n",
            "- openai/gpt-4o-2024-11-20\n",
            "- mistralai/mistral-large-2411\n",
            "- mistralai/mistral-large-2407\n",
            "- mistralai/pixtral-large-2411\n",
            "- x-ai/grok-vision-beta\n",
            "- infermatic/mn-inferor-12b\n",
            "- qwen/qwen-2.5-coder-32b-instruct:free\n",
            "- qwen/qwen-2.5-coder-32b-instruct\n",
            "- raifle/sorcererlm-8x22b\n",
            "- eva-unit-01/eva-qwen-2.5-32b\n",
            "- thedrummer/unslopnemo-12b\n",
            "- anthropic/claude-3.5-haiku:beta\n",
            "- anthropic/claude-3.5-haiku\n",
            "- anthropic/claude-3.5-haiku-20241022:beta\n",
            "- anthropic/claude-3.5-haiku-20241022\n",
            "- neversleep/llama-3.1-lumimaid-70b\n",
            "- anthracite-org/magnum-v4-72b\n",
            "- anthropic/claude-3.5-sonnet:beta\n",
            "- anthropic/claude-3.5-sonnet\n",
            "- x-ai/grok-beta\n",
            "- mistralai/ministral-8b\n",
            "- mistralai/ministral-3b\n",
            "- qwen/qwen-2.5-7b-instruct:free\n",
            "- qwen/qwen-2.5-7b-instruct\n",
            "- nvidia/llama-3.1-nemotron-70b-instruct\n",
            "- inflection/inflection-3-productivity\n",
            "- inflection/inflection-3-pi\n",
            "- google/gemini-flash-1.5-8b\n",
            "- thedrummer/rocinante-12b\n",
            "- anthracite-org/magnum-v2-72b\n",
            "- liquid/lfm-40b\n",
            "- meta-llama/llama-3.2-3b-instruct:free\n",
            "- meta-llama/llama-3.2-3b-instruct\n",
            "- meta-llama/llama-3.2-1b-instruct:free\n",
            "- meta-llama/llama-3.2-1b-instruct\n",
            "- meta-llama/llama-3.2-90b-vision-instruct\n",
            "- meta-llama/llama-3.2-11b-vision-instruct:free\n",
            "- meta-llama/llama-3.2-11b-vision-instruct\n",
            "- qwen/qwen-2.5-72b-instruct:free\n",
            "- qwen/qwen-2.5-72b-instruct\n",
            "- qwen/qwen-2.5-vl-72b-instruct\n",
            "- neversleep/llama-3.1-lumimaid-8b\n",
            "- openai/o1-preview\n",
            "- openai/o1-preview-2024-09-12\n",
            "- openai/o1-mini\n",
            "- openai/o1-mini-2024-09-12\n",
            "- mistralai/pixtral-12b\n",
            "- cohere/command-r-plus-08-2024\n",
            "- cohere/command-r-08-2024\n",
            "- qwen/qwen-2.5-vl-7b-instruct:free\n",
            "- qwen/qwen-2.5-vl-7b-instruct\n",
            "- sao10k/l3.1-euryale-70b\n",
            "- google/gemini-flash-1.5-8b-exp\n",
            "- ai21/jamba-1-5-mini\n",
            "- ai21/jamba-1-5-large\n",
            "- microsoft/phi-3.5-mini-128k-instruct\n",
            "- nousresearch/hermes-3-llama-3.1-70b\n",
            "- nousresearch/hermes-3-llama-3.1-405b\n",
            "- openai/chatgpt-4o-latest\n",
            "- sao10k/l3-lunaris-8b\n",
            "- aetherwiing/mn-starcannon-12b\n",
            "- openai/gpt-4o-2024-08-06\n",
            "- meta-llama/llama-3.1-405b:free\n",
            "- meta-llama/llama-3.1-405b\n",
            "- nothingiisreal/mn-celeste-12b\n",
            "- perplexity/llama-3.1-sonar-small-128k-online\n",
            "- perplexity/llama-3.1-sonar-large-128k-online\n",
            "- meta-llama/llama-3.1-8b-instruct:free\n",
            "- meta-llama/llama-3.1-8b-instruct\n",
            "- meta-llama/llama-3.1-405b-instruct\n",
            "- meta-llama/llama-3.1-70b-instruct\n",
            "- mistralai/codestral-mamba\n",
            "- mistralai/mistral-nemo:free\n",
            "- mistralai/mistral-nemo\n",
            "- openai/gpt-4o-mini\n",
            "- openai/gpt-4o-mini-2024-07-18\n",
            "- google/gemma-2-27b-it\n",
            "- alpindale/magnum-72b\n",
            "- google/gemma-2-9b-it:free\n",
            "- google/gemma-2-9b-it\n",
            "- 01-ai/yi-large\n",
            "- ai21/jamba-instruct\n",
            "- anthropic/claude-3.5-sonnet-20240620:beta\n",
            "- anthropic/claude-3.5-sonnet-20240620\n",
            "- sao10k/l3-euryale-70b\n",
            "- cognitivecomputations/dolphin-mixtral-8x22b\n",
            "- qwen/qwen-2-72b-instruct\n",
            "- mistralai/mistral-7b-instruct:free\n",
            "- mistralai/mistral-7b-instruct\n",
            "- nousresearch/hermes-2-pro-llama-3-8b\n",
            "- mistralai/mistral-7b-instruct-v0.3\n",
            "- microsoft/phi-3-mini-128k-instruct\n",
            "- microsoft/phi-3-medium-128k-instruct\n",
            "- neversleep/llama-3-lumimaid-70b\n",
            "- deepseek/deepseek-coder\n",
            "- google/gemini-flash-1.5\n",
            "- openai/gpt-4o\n",
            "- openai/gpt-4o:extended\n",
            "- meta-llama/llama-guard-2-8b\n",
            "- openai/gpt-4o-2024-05-13\n",
            "- allenai/olmo-7b-instruct\n",
            "- neversleep/llama-3-lumimaid-8b:extended\n",
            "- neversleep/llama-3-lumimaid-8b\n",
            "- sao10k/fimbulvetr-11b-v2\n",
            "- meta-llama/llama-3-8b-instruct\n",
            "- meta-llama/llama-3-70b-instruct\n",
            "- mistralai/mixtral-8x22b-instruct\n",
            "- microsoft/wizardlm-2-8x22b\n",
            "- google/gemini-pro-1.5\n",
            "- openai/gpt-4-turbo\n",
            "- cohere/command-r-plus\n",
            "- cohere/command-r-plus-04-2024\n",
            "- sophosympatheia/midnight-rose-70b\n",
            "- cohere/command\n",
            "- cohere/command-r\n",
            "- anthropic/claude-3-haiku:beta\n",
            "- anthropic/claude-3-haiku\n",
            "- anthropic/claude-3-opus:beta\n",
            "- anthropic/claude-3-opus\n",
            "- anthropic/claude-3-sonnet:beta\n",
            "- anthropic/claude-3-sonnet\n",
            "- cohere/command-r-03-2024\n",
            "- mistralai/mistral-large\n",
            "- openai/gpt-3.5-turbo-0613\n",
            "- openai/gpt-4-turbo-preview\n",
            "- nousresearch/nous-hermes-2-mixtral-8x7b-dpo\n",
            "- mistralai/mistral-medium\n",
            "- mistralai/mistral-small\n",
            "- mistralai/mistral-tiny\n",
            "- mistralai/mistral-7b-instruct-v0.2\n",
            "- google/gemini-pro-vision\n",
            "- mistralai/mixtral-8x7b-instruct\n",
            "- neversleep/noromaid-20b\n",
            "- anthropic/claude-2.1:beta\n",
            "- anthropic/claude-2.1\n",
            "- anthropic/claude-2:beta\n",
            "- anthropic/claude-2\n",
            "- undi95/toppy-m-7b\n",
            "- alpindale/goliath-120b\n",
            "- openrouter/auto\n",
            "- openai/gpt-3.5-turbo-1106\n",
            "- openai/gpt-4-1106-preview\n",
            "- google/palm-2-chat-bison-32k\n",
            "- google/palm-2-codechat-bison-32k\n",
            "- jondurbin/airoboros-l2-70b\n",
            "- openai/gpt-3.5-turbo-instruct\n",
            "- mistralai/mistral-7b-instruct-v0.1\n",
            "- pygmalionai/mythalion-13b\n",
            "- openai/gpt-3.5-turbo-16k\n",
            "- openai/gpt-4-32k\n",
            "- openai/gpt-4-32k-0314\n",
            "- mancer/weaver\n",
            "- huggingfaceh4/zephyr-7b-beta:free\n",
            "- anthropic/claude-2.0:beta\n",
            "- anthropic/claude-2.0\n",
            "- undi95/remm-slerp-l2-13b\n",
            "- google/palm-2-chat-bison\n",
            "- google/palm-2-codechat-bison\n",
            "- gryphe/mythomax-l2-13b\n",
            "- meta-llama/llama-2-70b-chat\n",
            "- openai/gpt-3.5-turbo\n",
            "- openai/gpt-3.5-turbo-0125\n",
            "- openai/gpt-4\n",
            "- openai/gpt-4-0314\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=OpenRouterLLM(),\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "i42jyHq2ESUf"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Tell me about Gatsby's life and experiences add year to the first.\"\n",
        "response = qa_chain(query)\n",
        "\n",
        "print(\"ðŸ“˜ Answer:\", response[\"result\"])\n",
        "print(\"\\nðŸ“„ Source snippet:\\n\", response[\"source_documents\"][0].page_content[:400])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GG0NIC9lFug_",
        "outputId": "ffb0b77d-acf2-4139-ce14-eccc7f10620d"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“˜ Answer: Gatsby's life and experiences are central to *The Great Gatsby*, revealing his rise from poverty to wealth, his unrelenting love for Daisy Buchanan, and his tragic pursuit of the American Dream. Hereâ€™s a timeline with key events, including the year you requested:\n",
            "\n",
            "1. **Early Life (Late 1890sâ€“1917)**: Born James Gatz in rural North Dakota, Gatsby grew up poor but ambitious. He reinvented himself as Jay Gatsby after meeting Dan Cody, a wealthy copper magnate, who became his mentor in 1907. Gatsby worked for Cody until 1912, when Cody died, leaving Gatsby nothing.  \n",
            "\n",
            "2. **Military Service and Meeting Daisy (1917â€“1918)**: During World War I, Gatsby trained as an officer in Louisville, Kentucky, where he met and fell in love with Daisy Fay (later Buchanan) in 1917. They briefly became engaged, but Gatsby was deployed overseas.  \n",
            "\n",
            "3. **Post-War and Oxford (1919)**: After the war, Gatsby attended Oxford for a short time (likely 1919) to fulfill a promise to Daisyâ€™s family, though his stay was brief. While there, he received a letter (as mentioned in your excerpt) informing him that Daisy had married Tom Buchanan.  \n",
            "\n",
            "4. **Prohibition Era Wealth (1920â€“1922)**: Gatsby amassed a fortune through bootlegging and other shady dealings, buying a mansion in West Egg around 1922 to be near Daisy. His extravagant parties were attempts to attract her attention.  \n",
            "\n",
            "5. **Reunion with Daisy (Summer 1922)**: Through Nick Carraway, Gatsby reunited with Daisy, reigniting their affair. The tension culminated in a confrontation with Tom at the Plaza Hotel (Chapter 7), leading to Daisyâ€™s choice to stay with Tom.  \n",
            "\n",
            "6. **Death (1922)**: Gatsby was shot by George Wilson, who mistakenly believed Gatsby killed his wife, Myrtle (unaware Tom Buchanan was the real culprit). Gatsby died alone, his funeral sparsely attended, symbolizing the emptiness of his dream.  \n",
            "\n",
            "Key themes include his idealized love for Daisy, the corruption of the American Dream, and the illusion of self-reinvention. The novelâ€™s events primarily unfold in the summer of 1922, as reflected in your excerpt (e.g., the July 1922 timetable).  \n",
            "\n",
            "Let me know if youâ€™d like deeper analysis of any event!\n",
            "\n",
            "ðŸ“„ Source snippet:\n",
            " The Great Gatsby1\u0018\u0018\n",
            "hand.\n",
            "That force took shape in the middle of spring with the ar-\n",
            "rival of Tom Buchanan. There was a wholesome bulkiness \n",
            "about his person and his position and Daisy was flattered. \n",
            "Doubtless there was a certain struggle and a certain relief. \n",
            "The letter reached Gatsby while he was still at Oxford.\n",
            "It was dawn now on Long Island and we went about open-\n",
            "ing the rest of the window\n"
          ]
        }
      ]
    }
  ]
}